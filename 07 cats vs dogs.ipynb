{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats_vs_dogs_small : 3\n",
      "cats_vs_dogs_small\\train : 2\n",
      "cats_vs_dogs_small\\validation : 2\n",
      "cats_vs_dogs_small\\test : 2\n",
      "cats_vs_dogs_small\\train\\cats : 1000\n",
      "cats_vs_dogs_small\\train\\dogs : 1000\n",
      "cats_vs_dogs_small\\validation\\cats : 500\n",
      "cats_vs_dogs_small\\validation\\dogs : 500\n",
      "cats_vs_dogs_small\\test\\cats : 500\n",
      "cats_vs_dogs_small\\test\\dogs : 500\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "original_dataset_dir = \"cats_vs_dogs/train\"\n",
    "\n",
    "dirs = []\n",
    "\n",
    "base_dir = \"cats_vs_dogs_small\"\n",
    "dirs.append(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "dirs.append(train_dir)\n",
    "validation_dir = os.path.join(base_dir, \"validation\")\n",
    "dirs.append(validation_dir)\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "dirs.append(test_dir)\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, \"cats\")\n",
    "dirs.append(train_cats_dir)\n",
    "train_dogs_dir = os.path.join(train_dir, \"dogs\")\n",
    "dirs.append(train_dogs_dir)\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, \"cats\")\n",
    "dirs.append(validation_cats_dir)\n",
    "validation_dogs_dir = os.path.join(validation_dir, \"dogs\")\n",
    "dirs.append(validation_dogs_dir)\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, \"cats\")\n",
    "dirs.append(test_cats_dir)\n",
    "test_dogs_dir = os.path.join(test_dir, \"dogs\")\n",
    "dirs.append(test_dogs_dir)\n",
    "\n",
    "for directory in dirs:\n",
    "    if not os.path.exists(directory):\n",
    "       os.mkdir(directory)\n",
    "\n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copy(src, dest)\n",
    "\n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copy(src, dest)\n",
    "\n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copy(src, dest)\n",
    "\n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copy(src, dest)\n",
    "\n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copy(src, dest)\n",
    "\n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copy(src, dest)\n",
    "\n",
    "for directory in dirs:\n",
    "    print(directory, \":\", len(os.listdir(directory)))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FIND DATA\n",
    "\n",
    "- PREPROCESSING\n",
    "    - Resize\n",
    "    - Labeling\n",
    "    - Balance\n",
    "    - Shuffle\n",
    "    - Train/Validation/Test - Split\n",
    "    \n",
    "- ANN ARCHITECTURE\n",
    "    - Layers\n",
    "        - Input / Output\n",
    "        - Activation Function\n",
    "    - Compile\n",
    "        - Optimizer\n",
    "        - Loss\n",
    "        - Metrics\n",
    "    \n",
    "- TRAINING\n",
    "    - fitting (incl. validation)\n",
    "    - plot\n",
    "    \n",
    "- EVALUATE\n",
    "\n",
    "- DEPLOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(\n",
    "    32, (3, 3),\n",
    "    activation=\"relu\",\n",
    "    input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(\n",
    "    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255.0) #normalization\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (150,150), #resizing / scaling all pictures to 150x150\n",
    "    batch_size = 20,\n",
    "    class_mode = \"binary\"\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (150,150), #resizing / scaling all pictures to 150x150\n",
    "    batch_size = 20,\n",
    "    class_mode = \"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 0.6070 - acc: 0.6665 - val_loss: 0.6060 - val_acc: 0.6580\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 36s 364ms/step - loss: 0.5645 - acc: 0.7125 - val_loss: 0.5849 - val_acc: 0.6890\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 0.5333 - acc: 0.7380 - val_loss: 0.5908 - val_acc: 0.6720\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 0.5125 - acc: 0.7500 - val_loss: 0.5598 - val_acc: 0.6980\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 38s 381ms/step - loss: 0.4949 - acc: 0.7625 - val_loss: 0.5845 - val_acc: 0.6980\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 0.4639 - acc: 0.7735 - val_loss: 0.5485 - val_acc: 0.7080\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 0.4447 - acc: 0.7885 - val_loss: 0.5563 - val_acc: 0.7030\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 38s 377ms/step - loss: 0.4144 - acc: 0.8100 - val_loss: 0.5704 - val_acc: 0.7110\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 0.3887 - acc: 0.8280 - val_loss: 0.5579 - val_acc: 0.7280\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 38s 382ms/step - loss: 0.3609 - acc: 0.8365 - val_loss: 0.5540 - val_acc: 0.7160\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 38s 380ms/step - loss: 0.3443 - acc: 0.8540 - val_loss: 0.5844 - val_acc: 0.7130\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 0.3237 - acc: 0.8710 - val_loss: 0.6454 - val_acc: 0.6870\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 0.2991 - acc: 0.8795 - val_loss: 0.5899 - val_acc: 0.7110\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 0.2817 - acc: 0.8840 - val_loss: 0.5995 - val_acc: 0.7250\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 38s 375ms/step - loss: 0.2601 - acc: 0.8900 - val_loss: 0.6039 - val_acc: 0.7210\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 0.2312 - acc: 0.9100 - val_loss: 0.6201 - val_acc: 0.7290\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 0.2127 - acc: 0.9205 - val_loss: 0.6830 - val_acc: 0.7210\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 0.1875 - acc: 0.9360 - val_loss: 0.6338 - val_acc: 0.7340\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 38s 377ms/step - loss: 0.1819 - acc: 0.9345 - val_loss: 0.6523 - val_acc: 0.7370\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 37s 374ms/step - loss: 0.1546 - acc: 0.9435 - val_loss: 0.6658 - val_acc: 0.7510\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 0.1328 - acc: 0.9575 - val_loss: 0.6704 - val_acc: 0.7440\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 0.1249 - acc: 0.9605 - val_loss: 0.7496 - val_acc: 0.7350\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 0.1035 - acc: 0.9700 - val_loss: 0.8927 - val_acc: 0.7240\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 38s 383ms/step - loss: 0.0975 - acc: 0.9690 - val_loss: 1.4545 - val_acc: 0.6650\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 37s 374ms/step - loss: 0.0804 - acc: 0.9785 - val_loss: 0.8326 - val_acc: 0.7340\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 0.0719 - acc: 0.9800 - val_loss: 0.8213 - val_acc: 0.7360\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 39s 386ms/step - loss: 0.0605 - acc: 0.9835 - val_loss: 1.0452 - val_acc: 0.7190\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 39s 390ms/step - loss: 0.0488 - acc: 0.9880 - val_loss: 0.9245 - val_acc: 0.7440\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 38s 380ms/step - loss: 0.0437 - acc: 0.9900 - val_loss: 0.9654 - val_acc: 0.7240\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 0.0387 - acc: 0.9880 - val_loss: 1.0221 - val_acc: 0.7470\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 100, #since batch size is 20, setting this number lower than 100 means you're not\n",
    "                            # processing all your data in each epoch\n",
    "                            # => 2000/20\n",
    "    epochs = 30,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 50 # => 1000/20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "ImagesShape: (10, 150, 150, 3)\n",
      "Labels: [1. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "1 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Illegal argument(s) to subplot: (0, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-22d37bda292a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m5\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DataScienceRetreat\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1255\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1257\u001b[1;33m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1258\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DataScienceRetreat\\lib\\site-packages\\matplotlib\\axes\\_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[1;31m# num - 1 for converting from MATLAB to python indexing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Illegal argument(s) to subplot: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Illegal argument(s) to subplot: (0, 0)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1.0/255.0,\n",
    "    rotation_range = 20\n",
    ")\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 10,\n",
    "    class_mode = \"binary\"\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "\n",
    "images, labels = next(generator)\n",
    "print(\"ImagesShape:\", images.shape)\n",
    "print(\"Labels:\", labels)\n",
    "\n",
    "#fig = plt.figure()\n",
    "#gs = gridspec.GridSpec(2, 5)\n",
    "\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    print(i//5 + 1, i%5 + 1)\n",
    "    fig.add_subplot(i//5,i % 5)\n",
    "    plt.imshow(image)\n",
    "    \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object generate at 0x000001DC043260A0>\n",
      "[1, 2]\n",
      "[3, 4]\n",
      "[5, 6]\n"
     ]
    }
   ],
   "source": [
    "def generate(batch_size):\n",
    "    i = 0\n",
    "    while True:\n",
    "        arr = []\n",
    "        for _ in range(batch_size):\n",
    "            i += 1\n",
    "            arr.append(i)\n",
    "        yield arr\n",
    "        \n",
    "g = generate(2)\n",
    "print(g)\n",
    "print(next(g))\n",
    "print(next(g))\n",
    "print(next(g))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
